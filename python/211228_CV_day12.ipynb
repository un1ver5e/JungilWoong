{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5606af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0772bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./DNN/googlenet/fig/\"\n",
    "filelist = os.listdir(path)\n",
    "filenames = []\n",
    "for i in filelist:\n",
    "    filename = path + i\n",
    "    filenames.append(filename)\n",
    "    \n",
    "model = \"./DNN/googlenet/bvlc_googlenet.caffemodel\"\n",
    "config = \"./DNN/googlenet/deploy.prototxt\"\n",
    "\n",
    "net = cv2.dnn.readNet(model, config)\n",
    "\n",
    "if net.empty():\n",
    "    print(\"net read failed\")\n",
    "    sys.exit()\n",
    "    \n",
    "classnames = []\n",
    "with open(\"./DNN/googlenet/classification_classes_ILSVRC2012.txt\", \"rt\") as f:\n",
    "    classnames = f.read().rstrip(\"\\n\").split(\"\\n\")\n",
    "    \n",
    "idx = 0\n",
    "while 1:\n",
    "    img = cv2.imread(filenames[idx])\n",
    "    \n",
    "    if img is None:\n",
    "        break\n",
    "    # color에 대한 scalefactor, 칼라를 스케일링 했냐\n",
    "    # mean = color normalization\n",
    "    blob = cv2.dnn.blobFromImage(img, 1, (224, 224), (104, 117, 123), \n",
    "                                 swapRB = False)\n",
    "    \n",
    "    net.setInput(blob)\n",
    "    prob = net.forward()\n",
    "    \n",
    "    out = prob.flatten()\n",
    "    classid = np.argmax(out)\n",
    "    confidence = out[classid]\n",
    "    name = classnames[classid]\n",
    "    \n",
    "    text = \"{},{}%\".format(name, round(confidence * 100, 2))\n",
    "    cv2.putText(img, text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.8,\n",
    "               (0, 0, 255), 1, cv2.LINE_AA)\n",
    "    \n",
    "    cv2.imshow(\"img\", img)\n",
    "    \n",
    "    idx += 1\n",
    "    \n",
    "    if idx >= len(filenames):\n",
    "        idx = 0\n",
    "        \n",
    "    if cv2.waitKey(2000) == 27:\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816e0423",
   "metadata": {},
   "source": [
    "### face recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0f2e61e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4a67f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"./DNN/opencv_face_detector/opencv_face_detector_uint8.pb\"\n",
    "config = \"./DNN/opencv_face_detector/opencv_face_detector.pbtxt\"\n",
    "\n",
    "net = cv2.dnn.readNet(model, config)\n",
    "\n",
    "if net.empty():\n",
    "    sys.exit(\"net read failed\")\n",
    "    \n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    sys.exit(\"video read failed\")\n",
    "    \n",
    "while 1:\n",
    "    ret, img = cap.read()\n",
    "    \n",
    "    if not ret:\n",
    "        break\n",
    "    blob = cv2.dnn.blobFromImage(img, 1, (300, 300), (104, 177, 123),\n",
    "                                swapRB = False)\n",
    "    net.setInput(blob)\n",
    "    out = net.forward() # ()가 공란이면 마지막 인덱스에 결과\n",
    "    \n",
    "    detect = out[0, 0, :, :]\n",
    "    h, w = img.shape[:2]\n",
    "    \n",
    "    for i in range(detect.shape[0]):\n",
    "        confidence = detect[i, 2]\n",
    "        \n",
    "        if confidence > 0.5:\n",
    "            x1 = int(detect[i, 3] * w)\n",
    "            y1 = int(detect[i, 4] * h)\n",
    "            x2 = int(detect[i, 5] * w)\n",
    "            y2 = int(detect[i, 6] * h)\n",
    "            \n",
    "            cv2.circle(img, (int((x2 + x1)/2), int((y2 + y1)/2)), \n",
    "                       int(np.linalg.norm()), (0, 0, 255), 5, cv2.LINE_AA)\n",
    "#             cv2.rectangle(img, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
    "            text = \"face, {}%\".format(round(confidence * 100, 2))\n",
    "            \n",
    "            cv2.putText(img, text, (x1, y1 - 3), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                       1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "    \n",
    "    cv2.imshow(\"img\", img)\n",
    "    \n",
    "    if cv2.waitKey(20) == 27:\n",
    "        break\n",
    "            \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f193e816",
   "metadata": {},
   "source": [
    "### yolo3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2fddf549",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a792498",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"./DNN/yolo_v3/yolov3.weights\"\n",
    "cfg = \"./DNN/yolo_v3/yolov3.cfg\"\n",
    "cls_ = \"./DNN/yolo_v3/coco.names\"\n",
    "\n",
    "imgfiles = glob.glob(\"./DNN/yolo_v3/fig/*.jpg\")\n",
    "\n",
    "net = cv2.dnn.readNet(model, cfg)\n",
    "\n",
    "if net.empty():\n",
    "    sys.exit(\"net read failed\")\n",
    "    \n",
    "l_class = []\n",
    "with open(cls_) as f:\n",
    "    l_class = f.read().rstrip(\"\\n\").rsplit(\"\\n\")\n",
    "    \n",
    "colors = np.random.uniform(0, 255, size = (80, 3))\n",
    "\n",
    "layer_names = net.getLayerNames()\n",
    "output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers()]\n",
    "\n",
    "for i in imgfiles:\n",
    "    img = cv2.imread(imgfiles[i])\n",
    "\n",
    "    \n",
    "    blob = cv2.dnn.blobFromImage(img, 1/255. (320, 320), (0, 0, 0),\n",
    "                                swapRB = True)\n",
    "    \n",
    "    net.setInput(blob)\n",
    "    outs = net.forward(output_layers)\n",
    "    \n",
    "    h, w = img.shape[:2]\n",
    "    \n",
    "    class_ids = []\n",
    "    confidences = []\n",
    "    boxes = []\n",
    "    \n",
    "    for out in outs:\n",
    "        for detection in out:\n",
    "            scores = detection[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence = scores[class_id]\n",
    "            \n",
    "            if confidence > 0.5:\n",
    "                cx = detection[0] * w\n",
    "                cy = detection[1] * h\n",
    "                bw = int(detection[2] * w)\n",
    "                bh = int(detection[3] * h)\n",
    "                \n",
    "                sx = int(cx - bw / 2)\n",
    "                sy = int(cy - bh / 2)\n",
    "                \n",
    "                boxes.append([sx, sy, bw, bh])\n",
    "                confidences.append(float(confidence))\n",
    "                class_ids.append(int(class_id))\n",
    "                \n",
    "    indices = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n",
    "    \n",
    "    for i in indices:\n",
    "        sx, sy, bw, bh = boxes[i]\n",
    "        label = \"{} : {}%\".format(l_class[class_ids[i]], \n",
    "                                  round(confidences[i] * 100, 2))\n",
    "        color = colors[class_ids[i]]\n",
    "        cv2.rectangle(img, (sx, sy, bw, bh), color, 2)\n",
    "        cv2.putText(img, label, (sx, sy - 3), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                   0.7, color, 1, cv2.LINE_AA)\n",
    "        \n",
    "    t, _ = net.getPerfProfile() # 주사선 속도 반환\n",
    "    label = \"inference time : {}\".format(t / cv2.getTickFrequency() * 1000)\n",
    "    cv2.putText(img, label, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1,\n",
    "               (255, 0, 0), 1, cv2.LINE_AA)\n",
    "    \n",
    "    cv2.imshow(\"img\", img)\n",
    "    \n",
    "    if cv2.waitKey(3000) == 27:\n",
    "        break\n",
    "        \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7fb4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = './yolo_v3/yolov3.weights'\n",
    "config = './yolo_v3/yolov3.cfg'\n",
    "class_label = './yolo_v3/coco.names'\n",
    "\n",
    "import glob\n",
    "\n",
    "img_files = glob.glob('./yolo_v3/fig/.jpg')\n",
    "\n",
    "cap = cv2.VideoCapture('./fig/video2.mp4')\n",
    "if not cap.isOpened():\n",
    "    print('video open failed')\n",
    "    sys.exit()\n",
    "\n",
    "net = cv2.dnn.readNet(model, config)\n",
    "if net.empty():\n",
    "    sys.exit(\"Net 404\")\n",
    "Class = []\n",
    "with open('./yolo_v3/coco.names', 'rt') as f:\n",
    "    Class = f.read().rstrip('\\n').split('\\n')\n",
    "\n",
    "Color = np.random.uniform(0, 255, size = (80,3))\n",
    "# print(Color.shape)\n",
    "\n",
    "Layers = net.getLayerNames()\n",
    "# print(Layers)\n",
    "output = [Layers[i-1] for i in net.getUnconnectedOutLayers()]\n",
    "# print(output)\n",
    "\n",
    "while True:\n",
    "    ret, img = cap.read()\n",
    "    blob = cv2.dnn.blobFromImage(img, 1/255., (320, 320), (104, 117, 123), swapRB = True)\n",
    "\n",
    "    net.setInput(blob)\n",
    "    Outs = net.forward(output)\n",
    "# print(Outs[0].shape)\n",
    "    h, w = img.shape[:2]\n",
    "\n",
    "    Classid =  []\n",
    "    Confidence = []\n",
    "    Bx = []\n",
    "\n",
    "    for out in Outs:\n",
    "        for det in out:\n",
    "            score = det[5:]\n",
    "            classid = np.argmax(score)\n",
    "            confidence = score[classid]\n",
    "\n",
    "            if confidence >= 0.5:\n",
    "                cx = (det[0] * w)\n",
    "                cy = (det[1] * h)\n",
    "                bw = int(det[2] * w)\n",
    "                bh = int(det[3] * h)\n",
    "\n",
    "                sx = int(cx - bw // 2)\n",
    "                sy = int(cy - bh // 2)\n",
    "\n",
    "                Bx.append([sx, sy, bw, bh])\n",
    "                Confidence.append(float(confidence))\n",
    "                Classid.append(classid)\n",
    "inD = cv2.dnn.NMSBoxes(Bx, Confidence, 0.5 ,0.4)\n",
    "    for i in inD:\n",
    "        sx, sy, bw, bh = Bx[i]\n",
    "        label = '{} : {}%'.format(Class[Classid[i]], round(Confidence[i]*100,2))\n",
    "        color = Color[Classid[i]]\n",
    "        cv2.rectangle(img, (sx,sy,bw,bh), color, 2)\n",
    "        cv2.putText(img, label, (sx, sy-10), cv2.FONT_HERSHEY_PLAIN, 2, (0, 0, 150), 1, cv2.LINEAA)\n",
    "\n",
    "    t,  = net.getPerfProfile()\n",
    "    label = 'inference time: {}'.format(round(t/cv2.getTickFrequency() * 1000, 2))\n",
    "    cv2.putText(img, label, (10, 30), cv2.FONT_HERSHEY_DUPLEX, 1, (255, 0, 155), 1, cv2.LINE_AA)\n",
    "\n",
    "    cv2.imshow('img', img)\n",
    "\n",
    "    if cv2.waitKey(2500) == 27:\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c79dd0",
   "metadata": {},
   "source": [
    "### shear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "21e977d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2f02924b",
   "metadata": {},
   "outputs": [],
   "source": [
    "src = cv2.imread(\"./fig/lenna.bmp\", 1)\n",
    "\n",
    "h, w = src.shape[:2]\n",
    "\n",
    "affine = np.array([[1, 0.5, 0],\n",
    "                   [0, 1, 0]], np.float32)\n",
    "\n",
    "dst = cv2.warpAffine(src, affine, (int(w * 1.5), h))\n",
    "\n",
    "cv2.imshow(\"src\", src)\n",
    "cv2.imshow(\"dst\", dst)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1d8de731",
   "metadata": {},
   "outputs": [],
   "source": [
    "src = cv2.imread(\"./fig/checkerboard.png\")\n",
    "\n",
    "src_point = np.array([[217, 50], [691, 47], [830, 517], [67, 526]], np.float32)\n",
    "dst_point = np.array([[0, 0], [w - 1, 0], [w - 1, h - 1], [0, h - 1]], np.float32)\n",
    "\n",
    "pers_coor = cv2.getPerspectiveTransform(src_point, dst_point)\n",
    "dst = cv2.warpPerspective(src, pers_coor, (w, h))\n",
    "\n",
    "cv2.imshow(\"src\", src)\n",
    "cv2.imshow(\"dst\", dst)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "00655fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실습\n",
    "src = cv2.imread(\"./fig/visitor_card.png\")\n",
    "\n",
    "src_point = np.array([[42, 73], [239, 25], [285, 122], [73, 194]], np.float32)\n",
    "dst_point = np.array([[0, 0], [w - 1, 0], [w - 1, h - 1], [0, h - 1]], np.float32)\n",
    "\n",
    "pers_coor = cv2.getPerspectiveTransform(src_point, dst_point)\n",
    "dst = cv2.warpPerspective(src, pers_coor, (w, h))\n",
    "\n",
    "cv2.imshow(\"src\", src)\n",
    "cv2.imshow(\"dst\", dst)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5527d0c",
   "metadata": {},
   "source": [
    "### 이미지를 흐물흐물하게"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a79558e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "src = cv2.imread(\"./fig/bamboo.jpg\")\n",
    "\n",
    "h, w = src.shape[:2]\n",
    "map2, map1 = np.indices((h, w), dtype = np.float32)\n",
    "map1 = map1 + 10 * np.tan(map2 / 32)\n",
    "\n",
    "dst = cv2.remap(src, map1, map2, cv2.INTER_CUBIC, borderMode = cv2.BORDER_DEFAULT)\n",
    "\n",
    "cv2.imshow(\"src\", src)\n",
    "cv2.imshow(\"dst\", dst)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192b21e3",
   "metadata": {},
   "source": [
    "### object tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dedbdeac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac5a3a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(\"./DNN/PETS2000.avi\")\n",
    "\n",
    "retback, back = cap.read()\n",
    "if not retback:\n",
    "    print(\"background read failed\")\n",
    "\n",
    "back = cv2.cvtColor(back, cv2.COLOR_BGR2GRAY)\n",
    "back = cv2.GaussianBlur(back, (0, 0), 1.0)\n",
    "fback = back.astype(np.float32)\n",
    "\n",
    "\n",
    "while 1:\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if not ret:\n",
    "        print(\"i r f\")\n",
    "        sys.exit()\n",
    "    \n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.GaussianBlur(gray, (0, 0), 1.0)\n",
    "    \n",
    "    cv2.accumulateWeighted(gray, fback, 0.001)\n",
    "    back = fback.astype(np.uint8)\n",
    "    \n",
    "#     frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    diff = cv2.absdiff(gray, back)\n",
    "    _, diff_th = cv2.threshold(diff, 30, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    cnts, _, stats, _ = cv2.connectedComponentsWithStats(diff_th)\n",
    "    \n",
    "    for i in range(1, cnts):\n",
    "        x, y, w, h, s = stats[i]\n",
    "        \n",
    "        if s < 300:\n",
    "            continue\n",
    "        cv2.rectangle(frame, (x, y, w, h), (0, 0, 255), 2)\n",
    "    \n",
    "    cv2.imshow(\"frame\", frame)\n",
    "    cv2.imshow(\"back\", back)\n",
    "    cv2.imshow(\"diff\", diff)\n",
    "    cv2.imshow(\"diff_th\", diff_th)\n",
    "    \n",
    "    if cv2.waitKey(30) == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
