{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1974a885",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import sys\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bcdee23",
   "metadata": {},
   "source": [
    "### 히스토그램 역행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deba8df1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "src = cv2.imread(\"./fig/cropland.png\")\n",
    "\n",
    "src_ycrcb = cv2.cvtColor(src, cv2.COLOR_BGR2YCrCb)\n",
    "\n",
    "x, y, w, h = cv2.selectROI(src)\n",
    "\n",
    "crop = src_ycrcb[y : y + h, x : x + w]\n",
    "\n",
    "size = [256, 256]\n",
    "ranges = [0, 256, 0, 256]\n",
    "\n",
    "hist = cv2.calcHist([crop], [1, 2], None, size, ranges)\n",
    "backproj = cv2.calcBackProject([src_ycrcb], [1, 2], hist, ranges, 1)\n",
    "\n",
    "dst = cv2.copyTo(src, backproj)\n",
    "\n",
    "cv2.imshow(\"src\", src)\n",
    "cv2.imshow(\"backproj\", backproj)\n",
    "cv2.imshow(\"dst\", dst)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60002fab",
   "metadata": {},
   "source": [
    "### 필터 - FILTERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3753446f",
   "metadata": {},
   "outputs": [],
   "source": [
    "src = cv2.imread(\"./fig/blue_eyes.png\", 0)\n",
    "\n",
    "# kernel = np.ones((3, 3), np.float32) / 9\n",
    "# dst = cv2.filter2D(src, -1, kernel) # 컨볼루션\n",
    "\n",
    "dst = cv2.blur(src, (7, 7))\n",
    "dst_g = cv2.GaussianBlur(src, (0, 0), 1)\n",
    "dst_sharp = cv2.addWeighted(src, 2, dst_g, -1, 0) # 0은 beta value\n",
    "dst_bila = cv2.bilateralFilter(src, -1, 5, 1) # 5은 sigmacolor, 1은 sigmaspace\n",
    "\n",
    "cv2.imshow(\"src\", src)\n",
    "cv2.imshow(\"dst\", dst)\n",
    "cv2.imshow(\"dst_g\", dst_g)\n",
    "cv2.imshow(\"dst_sharp\", dst_sharp)\n",
    "cv2.imshow(\"dst_bilateral\", dst_bila)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33eeacaa",
   "metadata": {},
   "source": [
    "### 기하학적 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b418a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "src = cv2.imread(\"./fig/puppy.bmp\", 1)\n",
    "\n",
    "affine = np.array([[1, 0, 20],\n",
    "                  [0, 1, 100]], np.float32)\n",
    "dst = cv2.warpAffine(src, affine, (0, 0)) # 0, 0은 확대 비율\n",
    "\n",
    "cv2.imshow(\"src\", src)\n",
    "cv2.imshow(\"dst\", dst)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc3b33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "src = cv2.imread(\"./fig/rose.jpg\", 1)\n",
    "\n",
    "dst_n = cv2.resize(src, (1920, 1080), interpolation = cv2.INTER_NEAREST)\n",
    "dst_c = cv2.resize(src, (1920, 1080), interpolation = cv2.INTER_CUBIC)\n",
    "\n",
    "cv2.imshow(\"src\", src)\n",
    "cv2.imshow(\"dst_n\", dst_n)\n",
    "cv2.imshow(\"dst_c\", dst_c)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9fbf2de",
   "metadata": {},
   "source": [
    "### 회전변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ec521a",
   "metadata": {},
   "outputs": [],
   "source": [
    "src = cv2.imread(\"./fig/puppy.bmp\", 1)\n",
    "\n",
    "h, w = src.shape[:2]\n",
    "\n",
    "cp = (w // 2, h // 2)\n",
    "affine = cv2.getRotationMatrix2D(cp, 20, 1)\n",
    "dst = cv2.warpAffine(src, affine, (0, 0))\n",
    "\n",
    "cv2.imshow(\"src\", src)\n",
    "cv2.imshow(\"dst_rot\", dst)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470f1292",
   "metadata": {},
   "source": [
    "# DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d6132f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d582c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# googleNET 영상 인식\n",
    "# imagesize = 224 x 224, color = BGR, mean(brightness) : (104, 117, 123)\n",
    "filename = \"./DNN/googlenet/fig/apple1.png\"\n",
    "img = cv2.imread(filename)\n",
    "\n",
    "if img is None:\n",
    "    print(\"image read failed\")\n",
    "    sys.exit()\n",
    "    \n",
    "# 사용할 네트워크(모델) - caffe 불러들이기\n",
    "model = \"./DNN/googlenet/bvlc_googlenet.caffemodel\"\n",
    "config = \"./DNN/googlenet/deploy.prototxt\"\n",
    "\n",
    "net = cv2.dnn.readNet(model, config)\n",
    "\n",
    "if net.empty():\n",
    "    print(\"Net read failed\")\n",
    "    sys.exit()\n",
    "    \n",
    "# classnames 불러오기\n",
    "classnames = []\n",
    "with open(\"./DNN/googlenet/classification_classes_ILSVRC2012.txt\") as f:\n",
    "    classnames = f.read().rstrip(\"\\n\").split(\"\\n\")\n",
    "# print(len(classnames)) -> 1000\n",
    "\n",
    "# image 불러올 때 전처리 : blob image 만들기\n",
    "# imagesize = 224 x 224, color = BGR, mean(brightness) : (104, 117, 123)\n",
    "# cv2.dnn.blobFromImage(\n",
    "# image[, scalefactor[, size[, mean[, swapRB[, crop[, ddepth]]]]]]) -> retval\n",
    "\n",
    "blob = cv2.dnn.blobFromImage(img, 1, (224, 224), (104, 117, 123),\n",
    "                            swapRB = False)\n",
    "\n",
    "# net instance에 input 넣기\n",
    "net.setInput(blob)\n",
    "\n",
    "# network 진행\n",
    "probability = net.forward()\n",
    "# print(type(probability), probability.shape, probability[:, 10])\n",
    "\n",
    "out = probability.flatten()\n",
    "classid = np.argmax(out)\n",
    "confidence = out[classid]\n",
    "# print(confidence) -> 0.9361577\n",
    "\n",
    "name = classnames[classid]\n",
    "# print(name) -> pomegranate\n",
    "\n",
    "text = \"({}, {}%)\".format(name, round(confidence * 100, 2))\n",
    "cv2.putText(img, text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255),\n",
    "           1, cv2.LINE_AA)\n",
    "\n",
    "cv2.imshow(\"img\", img)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b19b34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "file_list = os.listdir(\"./DNN/googlenet/fig/\")\n",
    "\n",
    "filenames = []\n",
    "for i in file_list:\n",
    "    file_name = \"./DNN/googlenet/fig/\" + i\n",
    "    filenames.append(file_name)\n",
    "\n",
    "idx = 0\n",
    "while 1:\n",
    "    img = cv2.imread(filenames[idx])\n",
    "\n",
    "    if img is None:\n",
    "        print(\"image read failed\")\n",
    "        sys.exit()\n",
    "\n",
    "    model = \"./DNN/googlenet/bvlc_googlenet.caffemodel\"\n",
    "    config = \"./DNN/googlenet/deploy.prototxt\"\n",
    "\n",
    "    net = cv2.dnn.readNet(model, config)\n",
    "\n",
    "    if net.empty():\n",
    "        print(\"Net read failed\")\n",
    "        sys.exit()\n",
    "\n",
    "    classnames = []\n",
    "    with open(\"./DNN/googlenet/classification_classes_ILSVRC2012.txt\") as f:\n",
    "        classnames = f.read().rstrip(\"\\n\").split(\"\\n\")\n",
    "    blob = cv2.dnn.blobFromImage(img, 1, (224, 224), (104, 117, 123),\n",
    "                                swapRB = False)\n",
    "\n",
    "    net.setInput(blob)\n",
    "\n",
    "    probability = net.forward()\n",
    "\n",
    "    out = probability.flatten()\n",
    "    classid = np.argmax(out)\n",
    "    confidence = out[classid]\n",
    "\n",
    "    name = classnames[classid]\n",
    "\n",
    "    text = \"({}, {}%)\".format(name, round(confidence * 100, 2))\n",
    "    cv2.putText(img, text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255),\n",
    "               1, cv2.LINE_AA)\n",
    "\n",
    "    cv2.imshow(\"img\", img)\n",
    "    \n",
    "    if cv2.waitKey(3000) == 27:\n",
    "        break\n",
    "        \n",
    "    idx += 1\n",
    "    \n",
    "    if idx >= len(filenames):\n",
    "        idx = 0\n",
    "        \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c114f3",
   "metadata": {},
   "source": [
    "# Face recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63cd12f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55197bef",
   "metadata": {},
   "source": [
    "### caffe face detection model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4978c9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"./DNN/googlenet/fig/mb.jpg\")\n",
    "\n",
    "model = \"./DNN/opencv_face_detector/res10_300x300_ssd_iter_140000_fp16.caffemodel\"\n",
    "config = \"./DNN/opencv_face_detector/deploy.prototxt\"\n",
    "\n",
    "# readNet(model[, config[, framework]]) -> retval\n",
    "facenet = cv2.dnn.readNet(model, config)\n",
    "\n",
    "if facenet.empty():\n",
    "    print(\"net open failed\")\n",
    "    sys.exit()\n",
    "    \n",
    "blob = cv2.dnn.blobFromImage(img, 1, # 1은 scalefactor\n",
    "                             (300, 300), # image size \n",
    "                             (104, 177, 123), # \n",
    "                             swapRB = False) # RGB로 할 것인가?\n",
    "\n",
    "facenet.setInput(blob)\n",
    "out = facenet.forward()\n",
    "# print(out.shape) -> (1, 1, 200, 7), idx0, idx1은 안씀\n",
    "\n",
    "detect = out[0, 0, :, :]\n",
    "h, w = img.shape[:2]\n",
    "\n",
    "for i in range(detect.shape[0]):\n",
    "    confidence = detect[i, 2]\n",
    "    \n",
    "    if confidence > 0.5:\n",
    "        x1 = int(detect[i, 3] * w)\n",
    "        y1 = int(detect[i, 4] * h)\n",
    "        x2 = int(detect[i, 5] * w)\n",
    "        y2 = int(detect[i, 6] * h)\n",
    "        \n",
    "        cv2.rectangle(img, (x1, y1), (x2, y2), (0, 0, 255))\n",
    "        text = \"face : {}%\".format(round(confidence * 100, 2))\n",
    "        \n",
    "        cv2.putText(img, text, (x1, y1 - 3), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                   0.8, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "\n",
    "if img is None:\n",
    "    print(\"image read failed\")\n",
    "    sys.exit()\n",
    "    \n",
    "cv2.imshow(\"img\", img)\n",
    "\n",
    "while 1:\n",
    "    if cv2.waitKey() == 27:\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef38ca6e",
   "metadata": {},
   "source": [
    "### pb face detection model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a44a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"./DNN/googlenet/fig/mb.jpg\")\n",
    "\n",
    "model = \"./DNN/opencv_face_detector/opencv_face_detector_uint8.pb\"\n",
    "config = \"./DNN/opencv_face_detector/opencv_face_detector.pbtxt\"\n",
    "\n",
    "# readNet(model[, config[, framework]]) -> retval\n",
    "facenet = cv2.dnn.readNet(model, config)\n",
    "\n",
    "if facenet.empty():\n",
    "    print(\"net open failed\")\n",
    "    sys.exit()\n",
    "    \n",
    "blob = cv2.dnn.blobFromImage(img, 1, # 1은 scalefactor\n",
    "                             (300, 300), # image size \n",
    "                             (104, 177, 123), # \n",
    "                             swapRB = False) # RGB로 할 것인가?\n",
    "\n",
    "facenet.setInput(blob)\n",
    "out = facenet.forward()\n",
    "# print(out.shape) -> (1, 1, 200, 7), idx0, idx1은 안씀\n",
    "\n",
    "detect = out[0, 0, :, :]\n",
    "h, w = img.shape[:2]\n",
    "\n",
    "for i in range(detect.shape[0]):\n",
    "    confidence = detect[i, 2]\n",
    "    \n",
    "    if confidence > 0.5:\n",
    "        x1 = int(detect[i, 3] * w)\n",
    "        y1 = int(detect[i, 4] * h)\n",
    "        x2 = int(detect[i, 5] * w)\n",
    "        y2 = int(detect[i, 6] * h)\n",
    "        \n",
    "        cv2.rectangle(img, (x1, y1), (x2, y2), (0, 0, 255))\n",
    "        text = \"face : {}%\".format(round(confidence * 100, 2))\n",
    "        \n",
    "        cv2.putText(img, text, (x1, y1 - 3), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                   0.8, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "\n",
    "if img is None:\n",
    "    print(\"image read failed\")\n",
    "    sys.exit()\n",
    "    \n",
    "cv2.imshow(\"img\", img)\n",
    "\n",
    "# while 1:\n",
    "#     if cv2.waitKey() == 27:\n",
    "#         break\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7842eef5",
   "metadata": {},
   "source": [
    "### webcam face detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f78156e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.isOpened()\n",
    "\n",
    "while 1:\n",
    "    returnvalue, frame = cap.read()\n",
    "    if not returnvalue:\n",
    "        print(\"video read failed\")\n",
    "        break\n",
    "\n",
    "    model = \"./DNN/opencv_face_detector/opencv_face_detector_uint8.pb\"\n",
    "    config = \"./DNN/opencv_face_detector/opencv_face_detector.pbtxt\"\n",
    "\n",
    "    # readNet(model[, config[, framework]]) -> retval\n",
    "    facenet = cv2.dnn.readNet(model, config)\n",
    "\n",
    "    if facenet.empty():\n",
    "        print(\"net open failed\")\n",
    "        sys.exit()\n",
    "\n",
    "    blob = cv2.dnn.blobFromImage(frame, 1, # 1은 scalefactor\n",
    "                                 (300, 300), # image size \n",
    "                                 (104, 177, 123), # \n",
    "                                 swapRB = False) # RGB로 할 것인가?\n",
    "\n",
    "    facenet.setInput(blob)\n",
    "    out = facenet.forward()\n",
    "    # print(out.shape) -> (1, 1, 200, 7), idx0, idx1은 안씀\n",
    "\n",
    "    detect = out[0, 0, :, :]\n",
    "    h, w = frame.shape[:2]\n",
    "\n",
    "    for i in range(detect.shape[0]):\n",
    "        confidence = detect[i, 2]\n",
    "\n",
    "        if confidence > 0.5:\n",
    "            x1 = int(detect[i, 3] * w)\n",
    "            y1 = int(detect[i, 4] * h)\n",
    "            x2 = int(detect[i, 5] * w)\n",
    "            y2 = int(detect[i, 6] * h)\n",
    "\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 0, 255))\n",
    "            text = \"face : {}%\".format(round(confidence * 100, 2))\n",
    "\n",
    "            cv2.putText(frame, text, (x1, y1 - 3), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                       0.8, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "\n",
    "    if frame is None:\n",
    "        print(\"image read failed\")\n",
    "        sys.exit()\n",
    "\n",
    "    cv2.imshow(\"img\", frame)\n",
    "\n",
    "    if cv2.waitKey(30) == 27:\n",
    "        break\n",
    "    \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2addc5",
   "metadata": {},
   "source": [
    "### object detection YOLO3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3084db92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cd1822b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"./DNN/yolo_v3/yolov3.weights\"\n",
    "config = \"./DNN/yolo_v3/yolov3.cfg\"\n",
    "class_labels = \"./DNN/yolo_v3/coco.names\"\n",
    "\n",
    "img_files = glob.glob(\"./DNN/yolo_v3/fig/*.jpg\")\n",
    "# print(img_files) ->\n",
    "# ['./DNN/yolo_v3/fig\\\\dog.jpg', './DNN/yolo_v3/fig\\\\kite.jpg', \n",
    "# './DNN/yolo_v3/fig\\\\person.jpg', './DNN/yolo_v3/fig\\\\sheep.jpg']\n",
    "\n",
    "net = cv2.dnn.readNet(model, config)\n",
    "\n",
    "if net.empty():\n",
    "    print(\"net read failed\")\n",
    "    sys.exit()\n",
    "    \n",
    "classes = []\n",
    "with open(class_labels, \"rt\") as f:\n",
    "    classes = f.read().rstrip(\"\\n\").split(\"\\n\")\n",
    "\n",
    "colors = np.random.uniform(0, 255, size = (80, 3))\n",
    "# print(colors)\n",
    "\n",
    "layer_names = net.getLayerNames()\n",
    "# print(layer_names)\n",
    "\n",
    "output_layers = [layer_names[i-1] for i in net.getUnconnectedOutLayers()]\n",
    "# print(output_layers)\n",
    "\n",
    "for i in img_files:\n",
    "    img = cv2.imread(i)\n",
    "    \n",
    "    if img is None:\n",
    "        continue\n",
    "        \n",
    "    blob = cv2.dnn.blobFromImage(img, 1/255., (320, 320), swapRB = True)\n",
    "    net.setInput(blob)\n",
    "    outs = net.forward(output_layers)\n",
    "    \n",
    "    h, w = img.shape[:2]\n",
    "    \n",
    "    class_ids = []\n",
    "    confidences = []\n",
    "    boxes = []\n",
    "    for out in outs:\n",
    "        for detection in out:\n",
    "            scores = detection[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence = scores[class_id]\n",
    "            \n",
    "            if confidence > 0.5:\n",
    "                cx = int(detection[0] * w)\n",
    "                cy = int(detection[1] * h)\n",
    "                bw = int(detection[2] * w)\n",
    "                bh = int(detection[3] * h)\n",
    "                \n",
    "                sx = int(cx - bw // 2)\n",
    "                sy = int(cy - bh // 2)\n",
    "                \n",
    "                boxes.append([sx, sy, bw, bh])\n",
    "                confidences.append(float(confidence))\n",
    "                class_ids.append(int(class_id))\n",
    "                \n",
    "    indices = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n",
    "    \n",
    "    for i in indices:\n",
    "#         i = i[0]\n",
    "        sx, sy, bw, bh = boxes[i]\n",
    "        label = \"{}:{}\".format(classes[class_ids[i]], round(confidences[i], 2))\n",
    "        \n",
    "        color = colors[class_ids[i]]\n",
    "        \n",
    "        cv2.rectangle(img, (sx, sy, bw, bh), color, 2)\n",
    "        cv2.putText(img, label, (sx, sy - 3), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                   0.8, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "    t, _ = net.getPerfProfile()\n",
    "    label = \"inference time : {}\".format(t * 1000.0 / cv2.getTickFrequency())\n",
    "    cv2.putText(img, label, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1,\n",
    "               (255, 0, 0), 1, cv2.LINE_AA)\n",
    "    \n",
    "    cv2.imshow(\"omg\", img)\n",
    "    cv2.waitKey()\n",
    "    \n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
